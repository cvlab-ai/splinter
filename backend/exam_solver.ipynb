{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from typing import List, Tuple\n",
    "from openvino.runtime import Dimension, Core\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path: str) -> np.ndarray:\n",
    "    image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    return cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "\n",
    "def show_image(image: np.ndarray, color=cv2.COLOR_GRAY2RGB) -> None:\n",
    "    if color is not None:\n",
    "        rgb_image = cv2.cvtColor(image, color)\n",
    "    else:\n",
    "        rgb_image = image\n",
    "    plt.figure(figsize=(10, 14))\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.imshow(rgb_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = read_image('exams/image--001.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_contours(image: np.ndarray, threshold: int = 80) -> np.ndarray:\n",
    "    new_image = image.copy()\n",
    "    lower_black = np.array([0])\n",
    "    upper_black = np.array([threshold])\n",
    "    mask = cv2.inRange(new_image, lowerb=lower_black, upperb=upper_black)\n",
    "    black_cnt = cv2.findContours(\n",
    "        mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[-2]\n",
    "    return black_cnt\n",
    "\n",
    "\n",
    "def find_squares(contours: np.ndarray, square_prop: float = 1.1) -> np.ndarray:\n",
    "    def is_square(candidate: List[int]) -> bool:\n",
    "        return max(candidate[2:])/min(candidate[2:]) <= square_prop\n",
    "    return [contour for contour in contours if is_square(cv2.boundingRect(contour))]\n",
    "\n",
    "\n",
    "def group_by_size(contours: np.ndarray, similarity_prop: float = 1.1) -> List[List[int]]:\n",
    "    groupped = [[]]\n",
    "    cont_idx, group_idx = 0, 0\n",
    "\n",
    "    contours = drop_insignificant(contours)\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "    while cont_idx < len(contours):\n",
    "        if len(groupped[group_idx]) == 0 or cv2.contourArea(groupped[group_idx][0])/cv2.contourArea(contours[cont_idx]) < similarity_prop:\n",
    "            groupped[group_idx].append(contours[cont_idx])\n",
    "        else:\n",
    "            groupped.append([contours[cont_idx]])\n",
    "            group_idx += 1\n",
    "        cont_idx += 1\n",
    "\n",
    "    return groupped\n",
    "\n",
    "\n",
    "def drop_insignificant(contours: np.ndarray, dropout: float = 400):\n",
    "    return [contour for contour in contours if cv2.contourArea(contour) >= dropout]\n",
    "\n",
    "\n",
    "def mark_contours(image: np.ndarray, contours: np.ndarray, frame_color: Tuple[int] = (0, 255, 0)) -> np.ndarray:\n",
    "    if len(image.shape) == 2:\n",
    "        new_image = cv2.cvtColor(image.copy(), cv2.COLOR_GRAY2RGB)\n",
    "    else:\n",
    "        new_image = image.copy()\n",
    "    for m_area in contours:\n",
    "        if type(m_area[0]) != int:\n",
    "            (xg, yg, wg, hg) = cv2.boundingRect(m_area)\n",
    "        else:\n",
    "            (xg, yg, wg, hg) = m_area\n",
    "        cv2.rectangle(new_image, (xg, yg), (xg+wg, yg+hg), frame_color, 2)\n",
    "    return new_image\n",
    "\n",
    "\n",
    "def calculate_rectangle(contours: np.ndarray, inside: bool = True) -> List[int]:\n",
    "    contours = [cv2.boundingRect(contour) for contour in contours]\n",
    "    right_x = [x[0] + x[2] for x in contours]\n",
    "    bottom_y = [x[1] + x[3] for x in contours]\n",
    "    if inside:\n",
    "        first_fun, second_fun = max, min\n",
    "    else:\n",
    "        first_fun, second_fun = min, max\n",
    "    x1 = first_fun(contours, key=lambda x: x[0])[0]\n",
    "    y1 = first_fun(contours, key=lambda x: x[1])[1]\n",
    "\n",
    "    x2 = second_fun(right_x)\n",
    "    y2 = second_fun(bottom_y)\n",
    "    w, h = abs(x1 - x2), abs(y1 - y2)\n",
    "    return [[min(x1, x2), min(y1, y2), w, h]]\n",
    "\n",
    "\n",
    "def calculate_personal_data(squares: List[int], answers: List[int]) -> List[int]:\n",
    "    return [squares[0][:3] + [abs(answers[0][1] - squares[0][1])]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours = detect_contours(image=image)\n",
    "\n",
    "square_contours = find_squares(contours)\n",
    "groupped_squares_contours = group_by_size(square_contours)[0]\n",
    "rectangle_inside_squares = calculate_rectangle(groupped_squares_contours)\n",
    "\n",
    "groupped_rectangle_contours = group_by_size(contours)[0]\n",
    "rectangle_answers_connected = calculate_rectangle(\n",
    "    groupped_rectangle_contours, inside=False)\n",
    "\n",
    "bound_personal = calculate_personal_data(\n",
    "    rectangle_inside_squares, rectangle_answers_connected)\n",
    "\n",
    "image_with_marked_squares = mark_contours(image, rectangle_inside_squares)\n",
    "image_with_marked_answers = mark_contours(\n",
    "    image_with_marked_squares, rectangle_answers_connected, (255, 0, 0))\n",
    "image_with_marked_personal = mark_contours(\n",
    "    image_with_marked_answers, bound_personal, (0, 0, 255))\n",
    "\n",
    "# show_image(image_with_marked_personal, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1, w1, h1 = rectangle_answers_connected[0]\n",
    "x2, y2, w2, h2 = bound_personal[0]\n",
    "answers_image = image[y1:y1+h1, x1:x1+w1]\n",
    "personal_image = image[y2:y2+h2, x2:x2+w2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_image(answers_image)\n",
    "# show_image(personal_image)\n",
    "\n",
    "def detect_lines(threshhold, kernel_size: Tuple[int]):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, kernel_size)\n",
    "    detect = cv2.morphologyEx(threshhold, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "    contours = cv2.findContours(detect, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours[0] if len(contours) == 2 else contours[1]\n",
    "\n",
    "answers_image[answers_image <= 170] = 0\n",
    "answers_image[answers_image > 170] = 255\n",
    "new_ans = answers_image.copy()\n",
    "\n",
    "thresh = cv2.threshold(new_ans, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "new_ans = cv2.cvtColor(new_ans, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "horizontal_contours = detect_lines(thresh, (40, 1))\n",
    "vertical_contours = detect_lines(thresh, (1, 30))\n",
    "\n",
    "cv2.drawContours(new_ans, horizontal_contours, -1, (0,255,0), 2)\n",
    "cv2.drawContours(new_ans, vertical_contours, -1, (255,0,0), 2);\n",
    "\n",
    "# show_image(new_ans, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_convert_threshold = 150\n",
    "\n",
    "personal_image[personal_image <= gray_convert_threshold] = 0\n",
    "personal_image[personal_image > gray_convert_threshold] = 255\n",
    "pers_copy = personal_image.copy()\n",
    "pers_copy[pers_copy < 300] = 255\n",
    "pers_copy = cv2.cvtColor(pers_copy, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "thresh = cv2.threshold(personal_image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "personal_horizontal = detect_lines(thresh, (30, 1))\n",
    "def calculate_line_length(line: List[List[int]]):\n",
    "    n_line = [l[0] for l in np.squeeze(line, axis=1)]\n",
    "    return max(n_line) - min(n_line)\n",
    "\n",
    "def split_horizontals_to_boxes(lines: List[List[List[int]]]) -> List[List[int]]:\n",
    "    boxes = []\n",
    "    idx = 0\n",
    "    while idx < len(lines)//2:\n",
    "        pair_of_lines = np.concatenate((lines[2*idx], lines[2*idx+1]), axis=0)\n",
    "        x, y, w, h = cv2.boundingRect(pair_of_lines)\n",
    "        boxes.append([x, y, w, h])\n",
    "        idx += 1\n",
    "    return boxes\n",
    "\n",
    "personal_horizontal = sorted(personal_horizontal, key=calculate_line_length, reverse=True)\n",
    "personal_horizontal_boxes = split_horizontals_to_boxes(personal_horizontal)\n",
    "pers_copy = mark_contours(personal_image, personal_horizontal_boxes)\n",
    "\n",
    "show_image(pers_copy, None)\n",
    "show_image(personal_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ie = Core()\n",
    "\n",
    "recognition_model = ie.read_model(model=\"models/text-recognition-resnet-fc.xml\", weights=\"models/text-recognition-resnet-fc.bin\")\n",
    "recognition_input_layer = recognition_model.inputs[0]\n",
    "recognition_input_shape = recognition_input_layer.partial_shape\n",
    "recognition_input_shape[3] = Dimension()\n",
    "recognition_model.reshape({recognition_input_layer: recognition_input_shape})\n",
    "\n",
    "compiled_recognition_model = ie.compile_model(model=recognition_model, device_name='AUTO')\n",
    "recognition_output_layer = compiled_recognition_model.outputs[0]\n",
    "\n",
    "# show_image(personal_image)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ce857a9f083f2a80be52ab117a18990ec9955985cc2c802c4427415a68ebec7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from openvino.runtime import Core\n",
    "from yaspin import yaspin\n",
    "from pathlib import Path\n",
    "import fitz as pdf\n",
    "import matplotlib.pyplot as plt\n",
    "from lexpy.trie import Trie\n",
    "from os import listdir\n",
    "from scipy.spatial.distance import hamming\n",
    "\n",
    "from openvino.runtime import Core\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ie = Core()\n",
    "\n",
    "model_dir = Path(\"model\")\n",
    "precision = \"FP16\"\n",
    "detection_model = \"horizontal-text-detection-0001\"\n",
    "recognition_model = \"text-recognition-0016\"\n",
    "base_model_dir = Path(\"~/open_model_zoo_models\").expanduser()\n",
    "omz_cache_dir = Path(\"~/open_model_zoo_cache\").expanduser()\n",
    "\n",
    "model_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_command = f\"omz_downloader --name {detection_model},{recognition_model} --output_dir {model_dir} --cache_dir {omz_cache_dir} --precision {precision}\"\n",
    "with yaspin(text=f\"Downloading {detection_model}, {recognition_model}\") as sp:\n",
    "    download_result = !$download_command\n",
    "    sp.text = f\"Finished downloading {detection_model}, {recognition_model}\"\n",
    "    sp.ok(\"âœ”\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_detection_path = Path(f\"{model_dir}/intel/{detection_model}/{precision}/{detection_model}\")\n",
    "text_recognition_encoder_path = Path(f\"{model_dir}/intel/{recognition_model}/{recognition_model}-encoder/{precision}/{recognition_model}-encoder\")\n",
    "text_recognition_decoder_path = Path(f\"{model_dir}/intel/{recognition_model}/{recognition_model}-decoder/{precision}/{recognition_model}-decoder\")\n",
    "assert Path(text_detection_path.with_suffix('.xml')).is_file(), \"Text detection model is not downloaded\"\n",
    "assert Path(text_recognition_encoder_path.with_suffix('.xml')).is_file(), \"Text recognition encoder is not downloaded\"\n",
    "assert Path(text_recognition_decoder_path.with_suffix('.xml')).is_file(), \"Text recognition decoder is not downlaoded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_model_file = ie.read_model(text_detection_path.with_suffix('.xml'))\n",
    "recognition_encoder_model_file = ie.read_model(text_recognition_encoder_path.with_suffix('.xml'))\n",
    "recognition_decoder_model_file = ie.read_model(text_recognition_decoder_path.with_suffix('.xml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdffile_name = \"175975.pdf\"\n",
    "doc = pdf.open(pdffile_name)\n",
    "pix = doc[11].get_pixmap(dpi=150)\n",
    "output = \"outfile.jpeg\"\n",
    "pix.save(output)\n",
    "image_file = \"outfile.jpeg\"\n",
    "image = cv2.imread(image_file)\n",
    "ih, iw, c = image.shape\n",
    "\n",
    "UUID_side = image[-int(ih/5):, int(iw/6):int(iw/6)+int(ih/5)]\n",
    "PID_side = image[-int(ih/6):, -int(ih/6):]\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_image_to_detection(image, model):\n",
    "    _, _, H, W = model.input(0).shape\n",
    "    resized_image = cv2.resize(image, (W, H))\n",
    "    return np.expand_dims(resized_image.transpose(2, 0, 1), 0)\n",
    "    \n",
    "\n",
    "UUID_side_resized = adjust_image_to_detection(UUID_side, detection_model_file)\n",
    "PID_side_resized = adjust_image_to_detection(PID_side, detection_model_file)\n",
    "\n",
    "assert UUID_side_resized.shape == PID_side_resized.shape == tuple(detection_model_file.input(0).shape), \"Invalid input shape\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_model_compiled = ie.compile_model(detection_model_file, device_name=\"CPU\")\n",
    "output_key = detection_model_compiled.output(\"boxes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UUID_boxes = detection_model_compiled([UUID_side_resized])[output_key]\n",
    "PID_boxes = detection_model_compiled([PID_side_resized])[output_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_empty = lambda box: box[~np.all(box == 0, axis = 1)]\n",
    "UUID_boxes_detected = remove_empty(UUID_boxes)\n",
    "PID_boxes_detected = remove_empty(PID_boxes)\n",
    "\n",
    "assert UUID_boxes_detected.shape[0] >= 1, \"No UUID detected\"\n",
    "assert PID_boxes_detected.shape[0] >= 1, \"No PID detected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PID_image_transposed = np.transpose(PID_side_resized[0], (1, 2, 0))\n",
    "x_min, y_min, x_max, y_max, prob = map(int, PID_boxes_detected[0])\n",
    "PID_cropped = PID_image_transposed[y_min:y_max, x_min:x_max]\n",
    "plt.imshow(PID_cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UUID_image_transposed = np.transpose(UUID_side_resized[0], (1, 2, 0))\n",
    "x_min, y_min, x_max, y_max, prob = map(int, UUID_boxes_detected[0])\n",
    "UUID_cropped = UUID_image_transposed[y_min:y_max, x_min:x_max]\n",
    "plt.imshow(UUID_cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_layer = recognition_encoder_model_file.input(0)\n",
    "partial_shape_encoder_input_layer = encoder_input_layer.partial_shape\n",
    "partial_shape_encoder_input_layer[3] = -1\n",
    "recognition_encoder_model_file.reshape({encoder_input_layer: partial_shape_encoder_input_layer})\n",
    "\n",
    "encoder_model_compiled = ie.compile_model(recognition_encoder_model_file, device_name=\"CPU\")\n",
    "decoder_model_compiled = ie.compile_model(recognition_decoder_model_file, device_name=\"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image_to_encoder(image, model):\n",
    "    N, C, H, W = model.input(0).partial_shape\n",
    "    IH, IW, IC = image.shape\n",
    "    scale_ratio = H.get_length() / IH\n",
    "    grayscale_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    resized_image = cv2.resize(\n",
    "        grayscale_image, None, fx=scale_ratio, fy=scale_ratio, interpolation=cv2.INTER_AREA\n",
    "    )\n",
    "    return resized_image[None, None,]\n",
    "    \n",
    "input_image_for_encoder = resize_image_to_encoder(UUID_cropped, encoder_model_compiled)\n",
    "output_key_encoder_features = encoder_model_compiled.output('features')\n",
    "output_key_encoder_hidden = encoder_model_compiled.output('decoder_hidden')\n",
    "\n",
    "encoder_output = encoder_model_compiled([input_image_for_encoder])\n",
    "\n",
    "encoder_output_features = encoder_output[output_key_encoder_features]\n",
    "encoder_output_hidden = encoder_output[output_key_encoder_hidden]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input_previous = decoder_model_compiled.input('decoder_input')\n",
    "decoder_input_features = decoder_model_compiled.input('features')\n",
    "decoder_input_hidden = decoder_model_compiled.input('hidden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_decoder_input_dict = {\n",
    "    decoder_input_previous: [0],\n",
    "    decoder_input_features: encoder_output_features,\n",
    "    decoder_input_hidden: encoder_output_hidden,\n",
    "}\n",
    "\n",
    "first_decoder_output = decoder_model_compiled(first_decoder_input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_output_hidden_key = decoder_model_compiled.output('decoder_hidden')\n",
    "decoder_output_value_key = decoder_model_compiled.output('decoder_output')\n",
    "\n",
    "decoder_output_hidden = first_decoder_output[decoder_output_hidden_key]\n",
    "decoder_output_value = first_decoder_output[decoder_output_value_key]\n",
    "\n",
    "alphabet = \"0123456789abcdefghijklmnopqrstuvwxyz\"\n",
    "alphabet = [symbol for symbol in alphabet]\n",
    "alphabet = [\"[START]\", \"[END]\", \" \", \"[NOT SURE]\"] + alphabet\n",
    "letter_idx = np.argmax(decoder_output_value)\n",
    "answer = \"\"\n",
    "while letter_idx not in [1, 2] and len(answer) < 10:\n",
    "    answer += alphabet[letter_idx]\n",
    "    decoder_input_dict = {\n",
    "        decoder_input_previous: [letter_idx],\n",
    "        decoder_input_features: encoder_output_features,\n",
    "        decoder_input_hidden: decoder_output_hidden,\n",
    "    }\n",
    "    decoder_output = decoder_model_compiled(decoder_input_dict)\n",
    "    decoder_output_hidden = decoder_output[decoder_output_hidden_key]\n",
    "    decoder_output_value = decoder_output[decoder_output_value_key]\n",
    "    letter_idx = np.argmax(decoder_output_value)\n",
    "\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_paths = {\n",
    "    \"encoder\": text_recognition_encoder_path,\n",
    "    \"decoder\": text_recognition_decoder_path,\n",
    "    \"detection\": text_detection_path\n",
    "}\n",
    "\n",
    "def map_UUID_to_trie(path):\n",
    "    trie = Trie()\n",
    "    files = [f[:-4] for f in listdir(path)]\n",
    "    trie.add_all(files)\n",
    "    return trie\n",
    "\n",
    "def resize_image_to_encoder(image, model):\n",
    "    N, C, H, W = model.input(0).partial_shape\n",
    "    IH, IW, IC = image.shape\n",
    "    scale_ratio = H.get_length() / IH\n",
    "    grayscale_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    resized_image = cv2.resize(\n",
    "        grayscale_image, None, fx=scale_ratio, fy=scale_ratio, interpolation=cv2.INTER_AREA\n",
    "    )\n",
    "    return resized_image[None, None,]\n",
    "\n",
    "def prepare_alphabet():\n",
    "    alphabet = \"0123456789abcdefghijklmnopqrstuvwxyz\"\n",
    "    alphabet = [symbol for symbol in alphabet]\n",
    "    return [\"[START]\", \"[END]\", \" \", \"[NOT SURE]\"] + alphabet\n",
    "\n",
    "def run_recognition(boxes, image, encoder_model, decoder_model):\n",
    "    alphabet = prepare_alphabet()\n",
    "    preprocessed_image = np.transpose(image[0], (1, 2, 0))\n",
    "    x_min, y_min, x_max, y_max, _ = map(int, boxes)\n",
    "    image_cropped = preprocessed_image[y_min:y_max, x_min:x_max]\n",
    "    image_resized = resize_image_to_encoder(image_cropped, encoder_model)\n",
    "    features_encoder, hidden_encoder = run_encoder_model(image_resized, encoder_model)\n",
    "    decoder_input_previous = decoder_model.input('decoder_input')\n",
    "    decoder_input_features = decoder_model.input('features')\n",
    "    decoder_input_hidden = decoder_model.input('hidden')\n",
    "    decoder_input_dict = {\n",
    "        decoder_input_previous: [0],\n",
    "        decoder_input_features: features_encoder,\n",
    "        decoder_input_hidden: hidden_encoder,\n",
    "    }\n",
    "    hidden_decoder, value_decoder = run_decoder_model(decoder_input_dict, decoder_model)\n",
    "    answer = \"\"\n",
    "    while value_decoder not in (1, 2) and len(answer) <= 13:\n",
    "        answer += alphabet[value_decoder]\n",
    "        decoder_input_dict[decoder_input_previous] = [value_decoder]\n",
    "        decoder_input_dict[decoder_input_hidden] = hidden_decoder\n",
    "        hidden_decoder, value_decoder = run_decoder_model(decoder_input_dict, decoder_model)\n",
    "    return answer\n",
    "\n",
    "def pipeline(image: np.array, model_paths: dict, UUID_proportion: float = 0.3, PID_proportion: float = 1/5):\n",
    "    detection_model_compiled, encoder_model_compiled, decoder_model_compiled = initialize_models(model_paths)\n",
    "    ih, iw, _ = image.shape\n",
    "    UUID_side = image[-int(ih*UUID_proportion):, :int(ih*UUID_proportion)]\n",
    "    PID_side = image[-int(ih*PID_proportion):, -int(ih*PID_proportion):]\n",
    "    UUID_PID = []\n",
    "    for name, partial_image in zip((\"UUID\", \"PID\"), (UUID_side, PID_side)):\n",
    "        preprocessed_image = adjust_image_to_detection(partial_image, detection_model_compiled)\n",
    "        boxes = detect_boxes(preprocessed_image, detection_model_compiled)\n",
    "        assert boxes.shape[0] >= 1, f\"Boxes shape: {boxes.shape}. Failed in {name} part\"\n",
    "        if boxes.shape[0] > 1:\n",
    "            if name == \"UUID\":\n",
    "                boxes = sorted(boxes, key=lambda value: value[3], reverse=True) \n",
    "            elif name == \"PID\":\n",
    "                boxes = sorted(boxes, key=lambda value: value[3], reverse=True)\n",
    "        for box in boxes:\n",
    "            answer = run_recognition(box, preprocessed_image, encoder_model_compiled, decoder_model_compiled)\n",
    "            if answer.isnumeric() and (name == \"UUID\" and len(answer) >= 7) or (name == \"PID\" and len(answer) < 2):\n",
    "                break\n",
    "        UUID_PID.append(answer)\n",
    "    return UUID_PID\n",
    "\n",
    "def check_if_correct(UUID, trie):\n",
    "    if UUID in trie:\n",
    "        return UUID\n",
    "    else:\n",
    "        possible_matches = trie.search_within_distance(UUID, dist=1)\n",
    "        if len(possible_matches) == 0:\n",
    "            possible_matches = trie.search_within_distance(UUID, dist=1)\n",
    "\n",
    "def initialize_models(models_paths: dict):\n",
    "    detection_model_file = ie.read_model(models_paths[\"detection\"].with_suffix('.xml'))\n",
    "    recognition_encoder_model_file = ie.read_model(models_paths[\"encoder\"].with_suffix('.xml'))\n",
    "    recognition_decoder_model_file = ie.read_model(models_paths[\"decoder\"].with_suffix('.xml'))\n",
    "    encoder_input_layer = recognition_encoder_model_file.input(0)\n",
    "    partial_shape_encoder_input_layer = encoder_input_layer.partial_shape\n",
    "    partial_shape_encoder_input_layer[3] = -1\n",
    "    recognition_encoder_model_file.reshape({encoder_input_layer: partial_shape_encoder_input_layer})\n",
    "\n",
    "    detection_model_compiled = ie.compile_model(detection_model_file, device_name=\"CPU\")\n",
    "    encoder_model_compiled = ie.compile_model(recognition_encoder_model_file, device_name=\"CPU\")\n",
    "    decoder_model_compiled = ie.compile_model(recognition_decoder_model_file, device_name=\"CPU\")\n",
    "    return detection_model_compiled, encoder_model_compiled, decoder_model_compiled\n",
    "\n",
    "def detect_boxes(image, model) -> np.array:\n",
    "    remove_empty = lambda box: box[~np.all(box == 0, axis = 1)]\n",
    "    output_key = model.output(\"boxes\")\n",
    "    return remove_empty(model([image])[output_key])\n",
    "\n",
    "def run_encoder_model(image, model):\n",
    "    output_key_encoder_features = model.output('features')\n",
    "    output_key_encoder_hidden = model.output('decoder_hidden')\n",
    "    encoder_output = model([image])\n",
    "    encoder_output_features = encoder_output[output_key_encoder_features]\n",
    "    encoder_output_hidden = encoder_output[output_key_encoder_hidden]\n",
    "    return encoder_output_features, encoder_output_hidden\n",
    "\n",
    "def run_decoder_model(inputs, model):\n",
    "    decoder_model_output = model(inputs)\n",
    "    decoder_output_hidden_key = model.output('decoder_hidden')\n",
    "    decoder_output_value_key = model.output('decoder_output')\n",
    "    decoder_output_hidden = decoder_model_output[decoder_output_hidden_key]\n",
    "    decoder_output_value = decoder_model_output[decoder_output_value_key]\n",
    "    return decoder_output_hidden, np.argmax(decoder_output_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failure at 8, details: Boxes shape: (0, 5). Failed in PID part\n",
      "Failure at 21, details: Boxes shape: (0, 5). Failed in PID part\n",
      "Failure at 23, details: Boxes shape: (0, 5). Failed in PID part\n",
      "Failure at 27, details: Boxes shape: (0, 5). Failed in PID part\n",
      "Failure at 30, details: Boxes shape: (0, 5). Failed in PID part\n",
      "{'12842262': [0, 2, 3, 1, 4], '13399024': [6, 7, 5, 10, 9], '16660625': [13, 15, 14, 12, 11], '30867773': [16, 19, 18], '34770711': [17, 20, 22], '35880174': [24, 26, 25], '41451620': [28, 31, 29, 34, 32], '46392465': [33, 35, 38, 36], '52927905': [37, 39, 40, 42], '72344783': [43, 41, 46, 44]}\n"
     ]
    }
   ],
   "source": [
    "trie = map_UUID_to_trie('/home/jakubdeb/repo/splinter/research/answers/answers')\n",
    "\n",
    "pdffile_name = \"scans/SKM_C364e22052617450.pdf\"\n",
    "doc = pdf.open(pdffile_name)\n",
    "scan_set = []\n",
    "for page in range(doc.page_count):\n",
    "    pix = doc[page].get_pixmap(dpi=150)\n",
    "    output = \"outfile.jpeg\"\n",
    "    pix.save(output)\n",
    "    image_file = \"outfile.jpeg\"\n",
    "    image = cv2.imread(image_file)\n",
    "\n",
    "    if np.mean(image) > 254.8:\n",
    "        scan_set.append([None, None])\n",
    "    else:\n",
    "        try:\n",
    "            scan_set.append(pipeline(image, model_paths))\n",
    "        except AssertionError as e:\n",
    "            scan_set.append([None, None])\n",
    "            print(f\"Failure at {page}, details: {e}\")\n",
    "\n",
    "\n",
    "for idx, (uuid, pid) in enumerate(scan_set):\n",
    "    if uuid is None and pid is None:\n",
    "        continue\n",
    "    elif uuid not in trie:\n",
    "        if idx > 0:\n",
    "            previous_exam = scan_set[idx-1] if (scan_set[idx-1][0] is not None) or idx == 1 else scan_set[idx-2] \n",
    "            if hamming(uuid, previous_exam[0]) <= 1/4 and previous_exam[0] in trie:\n",
    "                scan_set[idx][0] = previous_exam[0]\n",
    "        if idx < len(scan_set) - 1 and scan_set[idx][0] not in trie:    \n",
    "            next_exam = scan_set[idx+1] if (scan_set[idx+1][0] is not None) or idx == len(scan_set) - 1 else scan_set[idx+2] \n",
    "            if hamming(uuid, next_exam[0]) <= 1/4 and next_exam[0] in trie:\n",
    "                scan_set[idx][0] = next_exam[0]\n",
    "        if scan_set[idx][0] not in trie:\n",
    "            possible_matches = trie.search_within_distance(scan_set[idx][0], dist=1)\n",
    "            if len(possible_matches) == 1:\n",
    "                scan_set[idx][0] = possible_matches[0]\n",
    "            else:\n",
    "                print(f'DETECTED UUID: {uuid} POSSIBLE MATCHES: {possible_matches}, ABSOLUTE PAGE NO: {idx}') \n",
    "\n",
    "pages_to_exams = {}\n",
    "for idx, (uuid, pid) in enumerate(scan_set):\n",
    "    if uuid is None and pid is None:\n",
    "        continue\n",
    "    elif uuid in pages_to_exams.keys():\n",
    "        pages_to_exams[uuid].append([idx, pid])\n",
    "    else:\n",
    "        pages_to_exams[uuid] = [[idx, pid]]\n",
    "\n",
    "for key, value in pages_to_exams.items():\n",
    "    pages_to_exams[key] = [v[0] for v in sorted(value, key=lambda x: x[1])]\n",
    "\n",
    "for key, value in pages_to_exams.items():\n",
    "    output_doc = pdf.open()\n",
    "    for page in value:\n",
    "        output_doc.insert_pdf(doc, from_page=page, to_page=page)\n",
    "    output_doc.save(f'dataset/{key}.pdf')\n",
    "\n",
    "print(pages_to_exams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "248.55277161930803"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "pix = doc[8].get_pixmap(dpi=150)\n",
    "output = \"outfile.jpeg\"\n",
    "pix.save(output)\n",
    "output = 'outfile.jpeg' \n",
    "image = cv2.imread(output)\n",
    "UUID_side = image[-int(ih/3):, :int(ih/3)]\n",
    "PID_side = image[-int(ih/5):, -int(ih/5):]\n",
    "plt.imshow(PID_side)\n",
    "np.mean(image)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74283e06228d4494a659e92a437093ac62ef0b0f163ddec465853a074f32f723"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import sys\n",
    "from typing import List, Tuple\n",
    "from openvino.runtime import Dimension, Core\n",
    "\n",
    "sys.path.append(\"../generator\")\n",
    "from scratch_mark_generator import create_handwritten_circle, create_handwritten_cross, calculate_mask, create_handwritten_doodle, create_handwritten_tick, show_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path: str) -> np.ndarray:\n",
    "    image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    return cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "\n",
    "def show_image(image: np.ndarray, color=cv2.COLOR_GRAY2RGB) -> None:\n",
    "    if color is not None:\n",
    "        rgb_image = cv2.cvtColor(image, color)\n",
    "    else:\n",
    "        rgb_image = image\n",
    "    plt.figure(figsize=(10, 14))\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.imshow(rgb_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = read_image('exams/image--001.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_contours(image: np.ndarray, threshold: int = 80) -> np.ndarray:\n",
    "    new_image = image.copy()\n",
    "    lower_black = np.array([0])\n",
    "    upper_black = np.array([threshold])\n",
    "    mask = cv2.inRange(new_image, lowerb=lower_black, upperb=upper_black)\n",
    "    black_cnt = cv2.findContours(\n",
    "        mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[-2]\n",
    "    return black_cnt\n",
    "\n",
    "\n",
    "def find_squares(contours: np.ndarray, square_prop: float = 1.1) -> np.ndarray:\n",
    "    def is_square(candidate: List[int]) -> bool:\n",
    "        return max(candidate[2:])/min(candidate[2:]) <= square_prop\n",
    "    return [contour for contour in contours if is_square(cv2.boundingRect(contour))]\n",
    "\n",
    "\n",
    "def group_by_size(contours: np.ndarray, similarity_prop: float = 1.1) -> List[List[int]]:\n",
    "    groupped = [[]]\n",
    "    cont_idx, group_idx = 0, 0\n",
    "\n",
    "    contours = drop_insignificant(contours)\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "    while cont_idx < len(contours):\n",
    "        if len(groupped[group_idx]) == 0 or cv2.contourArea(groupped[group_idx][0])/cv2.contourArea(contours[cont_idx]) < similarity_prop:\n",
    "            groupped[group_idx].append(contours[cont_idx])\n",
    "        else:\n",
    "            groupped.append([contours[cont_idx]])\n",
    "            group_idx += 1\n",
    "        cont_idx += 1\n",
    "\n",
    "    return groupped\n",
    "\n",
    "\n",
    "def drop_insignificant(contours: np.ndarray, dropout: float = 400):\n",
    "    return [contour for contour in contours if cv2.contourArea(contour) >= dropout]\n",
    "\n",
    "\n",
    "def mark_contours(image: np.ndarray, contours: np.ndarray, frame_color: Tuple[int] = (0, 255, 0)) -> np.ndarray:\n",
    "    if len(image.shape) == 2:\n",
    "        new_image = cv2.cvtColor(image.copy(), cv2.COLOR_GRAY2RGB)\n",
    "    else:\n",
    "        new_image = image.copy()\n",
    "    for m_area in contours:\n",
    "        if type(m_area[0]) != int:\n",
    "            (xg, yg, wg, hg) = cv2.boundingRect(m_area)\n",
    "        else:\n",
    "            (xg, yg, wg, hg) = m_area\n",
    "        cv2.rectangle(new_image, (xg, yg), (xg+wg, yg+hg), frame_color, 2)\n",
    "    return new_image\n",
    "\n",
    "\n",
    "def calculate_rectangle(contours: np.ndarray, inside: bool = True) -> List[int]:\n",
    "    contours = [cv2.boundingRect(contour) for contour in contours]\n",
    "    right_x = [x[0] + x[2] for x in contours]\n",
    "    bottom_y = [x[1] + x[3] for x in contours]\n",
    "    if inside:\n",
    "        first_fun, second_fun = max, min\n",
    "    else:\n",
    "        first_fun, second_fun = min, max\n",
    "    x1 = first_fun(contours, key=lambda x: x[0])[0]\n",
    "    y1 = first_fun(contours, key=lambda x: x[1])[1]\n",
    "\n",
    "    x2 = second_fun(right_x)\n",
    "    y2 = second_fun(bottom_y)\n",
    "    w, h = abs(x1 - x2), abs(y1 - y2)\n",
    "    return [[min(x1, x2), min(y1, y2), w, h]]\n",
    "\n",
    "\n",
    "def calculate_personal_data(squares: List[int], answers: List[int]) -> List[int]:\n",
    "    return [squares[0][:3] + [abs(answers[0][1] - squares[0][1])]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours = detect_contours(image=image)\n",
    "\n",
    "square_contours = find_squares(contours)\n",
    "groupped_squares_contours = group_by_size(square_contours)[0]\n",
    "rectangle_inside_squares = calculate_rectangle(groupped_squares_contours)\n",
    "\n",
    "groupped_rectangle_contours = group_by_size(contours)[0]\n",
    "rectangle_answers_connected = calculate_rectangle(\n",
    "    groupped_rectangle_contours, inside=False)\n",
    "\n",
    "bound_personal = calculate_personal_data(\n",
    "    rectangle_inside_squares, rectangle_answers_connected)\n",
    "\n",
    "image_with_marked_squares = mark_contours(image, rectangle_inside_squares)\n",
    "image_with_marked_answers = mark_contours(\n",
    "    image_with_marked_squares, rectangle_answers_connected, (255, 0, 0))\n",
    "image_with_marked_personal = mark_contours(\n",
    "    image_with_marked_answers, bound_personal, (0, 0, 255))\n",
    "\n",
    "# show_image(image_with_marked_personal, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1, w1, h1 = rectangle_answers_connected[0]\n",
    "x2, y2, w2, h2 = bound_personal[0]\n",
    "answers_image = image[y1:y1+h1, x1:x1+w1]\n",
    "personal_image = image[y2:y2+h2, x2:x2+w2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_image(answers_image)\n",
    "# show_image(personal_image)\n",
    "\n",
    "def detect_lines(threshhold, kernel_size: Tuple[int]):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, kernel_size)\n",
    "    detect = cv2.morphologyEx(threshhold, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "    contours = cv2.findContours(detect, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours[0] if len(contours) == 2 else contours[1]\n",
    "\n",
    "answers_image[answers_image <= 170] = 0\n",
    "answers_image[answers_image > 170] = 255\n",
    "new_ans = answers_image.copy()\n",
    "\n",
    "thresh = cv2.threshold(new_ans, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "new_ans = cv2.cvtColor(new_ans, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "horizontal_contours = detect_lines(thresh, (40, 1))\n",
    "vertical_contours = detect_lines(thresh, (1, 30))\n",
    "\n",
    "cv2.drawContours(new_ans, horizontal_contours, -1, (0,255,0), 2)\n",
    "cv2.drawContours(new_ans, vertical_contours, -1, (255,0,0), 2);\n",
    "\n",
    "show_image(new_ans, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_box_coordinates(horizontal_contours, vertical_contours):\n",
    "    def calculate_lines_boundaries(lines):\n",
    "        boundaries = []\n",
    "        for line in lines:\n",
    "            x1 = min(line, key=lambda x: x[0])[0]\n",
    "            y1 = min(line, key=lambda x: x[1])[1]\n",
    "            x2 = max(line, key=lambda x: x[0])[0]\n",
    "            y2 = max(line, key=lambda x: x[1])[1]\n",
    "            boundaries.append(x1, y1, x2, y2)\n",
    "        return boundaries\n",
    "    \n",
    "    def calculate_cross_points(first_line, second_line, perpendicular_lines: list) -> list:\n",
    "        if first_line[2] < second_line[0]:\n",
    "            return [] \n",
    "        horizontal_boundaries = calculate_lines_boundaries([first_line, second_line]) # horizontal\n",
    "        perpendicular_boundaries = calculate_lines_boundaries(perpendicular_lines)\n",
    "        cross_points = []\n",
    "        for line_idx in range(len(perpendicular_boundaries)):\n",
    "            vertical_boundaries = perpendicular_boundaries[line_idx] # vertical\n",
    "            for hb in horizontal_boundaries:\n",
    "                if hb[0] <= (vertical_boundaries[0] + vertical_boundaries[2])/2 <= hb[2] and \\\n",
    "                vertical_boundaries[1] <= (vertical_boundaries[1] + vertical_boundaries[3])/2 <= vertical_boundaries[3]:\n",
    "                    cross_points.append([(vertical_boundaries[0] + vertical_boundaries[2])/2, (hb[1] + hb[3])/2])\n",
    "        return cross_points\n",
    "    \n",
    "    def sort_horizontals(horizontal_contours):\n",
    "        return sorted(horizontal_contours, key=lambda x: x[0])\n",
    "\n",
    "    def sort_vertical(vertical_contours):\n",
    "        temp_vertical = sorted(vertical_contours, key=lambda x: (x[0], x[1]))\n",
    "        return temp_vertical[::2] + temp_vertical[1::2]\n",
    "\n",
    "calculate_box_coordinates(horizontal_contours=horizontal_contours, vertical_contours=vertical_contours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_line_length(line: List[List[int]]):\n",
    "    n_line = [l[0] for l in np.squeeze(line, axis=1)]\n",
    "    return max(n_line) - min(n_line)\n",
    "\n",
    "def split_horizontals_to_boxes(lines: List[List[List[int]]]) -> List[List[int]]:\n",
    "    boxes = []\n",
    "    idx = 0\n",
    "    while idx < len(lines)//2:\n",
    "        pair_of_lines = np.concatenate((lines[2*idx], lines[2*idx+1]), axis=0)\n",
    "        x, y, w, h = cv2.boundingRect(pair_of_lines)\n",
    "        boxes.append([x, y, w, h])\n",
    "        idx += 1\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_convert_threshold = 150\n",
    "\n",
    "pers_copy = personal_image.copy()\n",
    "pers_copy[pers_copy <= gray_convert_threshold] = 0\n",
    "pers_copy[pers_copy > gray_convert_threshold] = 255\n",
    "\n",
    "thresh = cv2.threshold(pers_copy, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "pers_copy = cv2.cvtColor(pers_copy, cv2.COLOR_GRAY2RGB)\n",
    "personal_horizontal = detect_lines(thresh, (30, 1))\n",
    "\n",
    "personal_horizontal = sorted(personal_horizontal, key=calculate_line_length, reverse=True)\n",
    "personal_horizontal_boxes = split_horizontals_to_boxes(personal_horizontal)\n",
    "# pers_copy = mark_contours(personal_image, personal_horizontal_boxes)\n",
    "\n",
    "# show_image(pers_copy, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ie = Core()\n",
    "\n",
    "letters = '~ !\"#$%&\\'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[]^_abcdefghijklmnopqrstuvwxyz{|}~£'\n",
    "\n",
    "recognition_model = ie.read_model(model=\"models/handwritten-english-recognition-0001.xml\", weights=\"models/handwritten-english-recognition-0001.bin\")\n",
    "\n",
    "compiled_recognition_model = ie.compile_model(model=recognition_model, device_name='AUTO')\n",
    "recognition_input_layer = compiled_recognition_model.input(0)\n",
    "recognition_output_layer = compiled_recognition_model.output(0)\n",
    "\n",
    "# show_image(personal_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_lines(image: np.ndarray, lines: List[List[int]], color = 255) -> np.ndarray:\n",
    "    for line in lines:\n",
    "        line = np.squeeze(line, axis=1)\n",
    "        x1 = min(line, key=lambda x: x[0])[0]\n",
    "        y1 = min(line, key=lambda x: x[1])[1]\n",
    "        x2 = max(line, key=lambda x: x[0])[0]\n",
    "        y2 = max(line, key=lambda x: x[1])[1]\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), color, -1)\n",
    "\n",
    "def decode(preds, character_list):\n",
    "    \"\"\" convert text-index into text-label. \"\"\"\n",
    "    texts = []\n",
    "    # Select max probability (greedy decoding) then decode index to character\n",
    "    preds_index = np.argmax(preds, 2) # WBD - > WB\n",
    "    preds_index = preds_index.transpose(1, 0) # WB -> BW\n",
    "    preds_index_reshape = preds_index.reshape(-1) # B*W\n",
    "\n",
    "    char_list = []\n",
    "    odds_list = []\n",
    "    for i in range(len(preds_index_reshape)):\n",
    "        if preds_index_reshape[i] != 0 and (not (i > 0 and preds_index_reshape[i - 1] == preds_index_reshape[i])):\n",
    "            char_list.append(character_list[preds_index_reshape[i]])\n",
    "            odds_list.append(max(preds[preds_index_reshape[i]][0]))\n",
    "    text = ''.join(char_list)\n",
    "    texts.append(text)\n",
    "    return texts # , odds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_convert_threshold = 175\n",
    "\n",
    "gray_personal_copy = personal_image.copy()\n",
    "gray_personal_copy[gray_personal_copy <= gray_convert_threshold] = 0\n",
    "gray_personal_copy[gray_personal_copy > gray_convert_threshold] = 255\n",
    "show_image(gray_personal_copy)\n",
    "\n",
    "personal_horizontal = detect_lines(thresh, (20, 1))\n",
    "\n",
    "remove_lines(gray_personal_copy, personal_horizontal)\n",
    "\n",
    "k1 = (4,1)\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, k1)\n",
    "i_b, i_c, i_h, i_w = recognition_input_layer.partial_shape\n",
    "i_h, i_w = i_h.get_length(), i_w.get_length()\n",
    "for box in personal_horizontal_boxes:\n",
    "    x, y, w, h = box\n",
    "    crop = gray_personal_copy[y:y+h, x:x+w]\n",
    "    thresh = cv2.threshold(crop, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "    personal_vertical = detect_lines(thresh, (1, 14))\n",
    "    personal_horizontal = detect_lines(thresh, (30, 1))\n",
    "    remove_lines(crop, personal_vertical)\n",
    "    remove_lines(crop, personal_horizontal)\n",
    "    ratio = i_h/h\n",
    "    crop = cv2.resize(crop, (int(ratio*w), i_h), interpolation=cv2.INTER_AREA)[None]\n",
    "    crop = np.pad(crop, ((0, 0), (0, 0), (0, i_w - int(ratio*w))), mode='edge')[None]\n",
    "    results = compiled_recognition_model([crop])[recognition_output_layer]\n",
    "    results = decode(results, letters)\n",
    "    results = np.squeeze(results)\n",
    "    \n",
    "    show_image(crop[0][0])\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_input(image_name, height, width):\n",
    "#     src = cv2.imread(image_name, cv2.IMREAD_GRAYSCALE)\n",
    "#     ratio = float(src.shape[1]) / float(src.shape[0])\n",
    "#     tw = int(height * ratio)\n",
    "#     rsz = cv2.resize(src, (tw, height), interpolation=cv2.INTER_AREA)\n",
    "#     # [h,w] -> [c,h,w]\n",
    "#     img = rsz[None, :, :]\n",
    "#     _, h, w = img.shape\n",
    "#     # right edge padding\n",
    "#     pad_img = np.pad(img, ((0, 0), (0, height - h), (0, width - w)), mode='edge')\n",
    "#     return pad_img\n",
    "\n",
    "# input = preprocess_input('exams/handwritten_english_test.png', i_h, i_w)[None]\n",
    "# results = compiled_recognition_model([input])[recognition_output_layer]\n",
    "# print(decode(results, letters))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ce857a9f083f2a80be52ab117a18990ec9955985cc2c802c4427415a68ebec7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

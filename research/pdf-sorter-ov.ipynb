{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from openvino.runtime import Core\n",
    "from yaspin import yaspin\n",
    "from pathlib import Path\n",
    "import fitz as pdf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from openvino.runtime import Core\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ie = Core()\n",
    "\n",
    "model_dir = Path(\"model\")\n",
    "precision = \"FP16\"\n",
    "detection_model = \"horizontal-text-detection-0001\"\n",
    "recognition_model = \"text-recognition-0016\"\n",
    "base_model_dir = Path(\"~/open_model_zoo_models\").expanduser()\n",
    "omz_cache_dir = Path(\"~/open_model_zoo_cache\").expanduser()\n",
    "\n",
    "model_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_command = f\"omz_downloader --name {detection_model},{recognition_model} --output_dir {model_dir} --cache_dir {omz_cache_dir} --precision {precision}\"\n",
    "with yaspin(text=f\"Downloading {detection_model}, {recognition_model}\") as sp:\n",
    "    download_result = !$download_command\n",
    "    sp.text = f\"Finished downloading {detection_model}, {recognition_model}\"\n",
    "    sp.ok(\"âœ”\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_detection_path = Path(f\"{model_dir}/intel/{detection_model}/{precision}/{detection_model}\")\n",
    "text_recognition_encoder_path = Path(f\"{model_dir}/intel/{recognition_model}/{recognition_model}-encoder/{precision}/{recognition_model}-encoder\")\n",
    "text_recognition_decoder_path = Path(f\"{model_dir}/intel/{recognition_model}/{recognition_model}-decoder/{precision}/{recognition_model}-decoder\")\n",
    "assert Path(text_detection_path.with_suffix('.xml')).is_file(), \"Text detection model is not downloaded\"\n",
    "assert Path(text_recognition_encoder_path.with_suffix('.xml')).is_file(), \"Text recognition encoder is not downloaded\"\n",
    "assert Path(text_recognition_decoder_path.with_suffix('.xml')).is_file(), \"Text recognition decoder is not downlaoded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_model_file = ie.read_model(text_detection_path.with_suffix('.xml'))\n",
    "recognition_encoder_model_file = ie.read_model(text_recognition_encoder_path.with_suffix('.xml'))\n",
    "recognition_decoder_model_file = ie.read_model(text_recognition_decoder_path.with_suffix('.xml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = \"outfile.jpeg\"\n",
    "image = cv2.imread(image_file)\n",
    "ih, iw, c = image.shape\n",
    "\n",
    "UUID_side = image[-int(ih/5):, int(iw/5):int(iw/5)+int(ih/5)]\n",
    "PID_side = image[-int(ih/5):, -int(ih/5):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_image_to_detection(image, shape):\n",
    "    _, _, H, W = shape\n",
    "    resized_image = cv2.resize(image, (W, H))\n",
    "    return np.expand_dims(resized_image.transpose(2, 0, 1), 0)\n",
    "    \n",
    "\n",
    "detection_input_layer_shape = detection_model_file.input(0).shape\n",
    "\n",
    "UUID_side_resized = adjust_image_to_detection(UUID_side, detection_input_layer_shape)\n",
    "PID_side_resized = adjust_image_to_detection(PID_side, detection_input_layer_shape)\n",
    "\n",
    "assert UUID_side_resized.shape == PID_side_resized.shape == tuple(detection_input_layer_shape), \"Invalid input shape\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_model_compiled = ie.compile_model(detection_model_file, device_name=\"CPU\")\n",
    "output_key = detection_model_compiled.output(\"boxes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UUID_boxes = detection_model_compiled([UUID_side_resized])[output_key]\n",
    "PID_boxes = detection_model_compiled([PID_side_resized])[output_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_empty = lambda box: box[~np.all(box == 0, axis = 1)]\n",
    "UUID_boxes_detected = remove_empty(UUID_boxes)\n",
    "PID_boxes_detected = remove_empty(PID_boxes)\n",
    "\n",
    "assert UUID_boxes_detected.shape[0] >= 1, \"No UUID detected\"\n",
    "assert PID_boxes_detected.shape[0] >= 1, \"No PID detected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PID_image_transposed = np.transpose(PID_side_resized[0], (1, 2, 0))\n",
    "x_min, y_min, x_max, y_max, prob = map(int, PID_boxes_detected[0])\n",
    "PID_cropped = PID_image_transposed[y_min:y_max, x_min:x_max]\n",
    "plt.imshow(PID_cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UUID_image_transposed = np.transpose(UUID_side_resized[0], (1, 2, 0))\n",
    "x_min, y_min, x_max, y_max, prob = map(int, UUID_boxes_detected[0])\n",
    "UUID_cropped = UUID_image_transposed[y_min:y_max, x_min:x_max]\n",
    "plt.imshow(UUID_cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_layer = recognition_encoder_model_file.input(0)\n",
    "partial_shape_encoder_input_layer = encoder_input_layer.partial_shape\n",
    "partial_shape_encoder_input_layer[3] = -1\n",
    "recognition_encoder_model_file.reshape({encoder_input_layer: partial_shape_encoder_input_layer})\n",
    "\n",
    "encoder_model_compiled = ie.compile_model(recognition_encoder_model_file, device_name=\"CPU\")\n",
    "decoder_model_compiled = ie.compile_model(recognition_decoder_model_file, device_name=\"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image_to_encoder(image, model_shape):\n",
    "    N, C, H, W = model_shape\n",
    "    IH, IW, IC = image.shape\n",
    "    scale_ratio = H.get_length() / IH\n",
    "    grayscale_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    resized_image = cv2.resize(\n",
    "        grayscale_image, None, fx=scale_ratio, fy=scale_ratio, interpolation=cv2.INTER_AREA\n",
    "    )\n",
    "    return resized_image[None, None,]\n",
    "    \n",
    "\n",
    "encoder_input_model_shape = encoder_model_compiled.input(0).partial_shape\n",
    "input_image_for_encoder = resize_image_to_encoder(UUID_cropped, encoder_input_model_shape)\n",
    "output_key_encoder_features = encoder_model_compiled.output('features')\n",
    "output_key_encoder_hidden = encoder_model_compiled.output('decoder_hidden')\n",
    "\n",
    "encoder_output = encoder_model_compiled([input_image_for_encoder])\n",
    "\n",
    "encoder_output_features = encoder_output[output_key_encoder_features]\n",
    "encoder_output_hidden = encoder_output[output_key_encoder_hidden]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input_previous = decoder_model_compiled.input('decoder_input')\n",
    "decoder_input_features = decoder_model_compiled.input('features')\n",
    "decoder_input_hidden = decoder_model_compiled.input('hidden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_decoder_input_dict = {\n",
    "    decoder_input_previous: [0],\n",
    "    decoder_input_features: encoder_output_features,\n",
    "    decoder_input_hidden: encoder_output_hidden,\n",
    "}\n",
    "\n",
    "first_decoder_output = decoder_model_compiled(first_decoder_input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_output_hidden_key = decoder_model_compiled.output('decoder_hidden')\n",
    "decoder_output_value_key = decoder_model_compiled.output('decoder_output')\n",
    "\n",
    "decoder_output_hidden = first_decoder_output[decoder_output_hidden_key]\n",
    "decoder_output_value = first_decoder_output[decoder_output_value_key]\n",
    "\n",
    "alphabet = \"0123456789abcdefghijklmnopqrstuvwxyz\"\n",
    "alphabet = [symbol for symbol in alphabet]\n",
    "alphabet = [\"[START]\", \"[END]\", \" \", \"[NOT SURE]\"] + alphabet\n",
    "letter_idx = np.argmax(decoder_output_value)\n",
    "answer = \"\"\n",
    "while letter_idx not in [1, 2] and len(answer) < 10:\n",
    "    answer += alphabet[letter_idx]\n",
    "    decoder_input_dict = {\n",
    "        decoder_input_previous: [letter_idx],\n",
    "        decoder_input_features: encoder_output_features,\n",
    "        decoder_input_hidden: decoder_output_hidden,\n",
    "    }\n",
    "    decoder_output = decoder_model_compiled(decoder_input_dict)\n",
    "    decoder_output_hidden = decoder_output[decoder_output_hidden_key]\n",
    "    decoder_output_value = decoder_output[decoder_output_value_key]\n",
    "    letter_idx = np.argmax(decoder_output_value)\n",
    "\n",
    "print(answer)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74283e06228d4494a659e92a437093ac62ef0b0f163ddec465853a074f32f723"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

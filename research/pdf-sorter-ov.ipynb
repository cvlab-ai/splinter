{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from openvino.runtime import Core\n",
    "from yaspin import yaspin\n",
    "from pathlib import Path\n",
    "import fitz as pdf\n",
    "import matplotlib.pyplot as plt\n",
    "from lexpy.trie import Trie\n",
    "from os import listdir\n",
    "from scipy.spatial.distance import hamming\n",
    "\n",
    "from openvino.runtime import Core\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ie = Core()\n",
    "\n",
    "model_dir = Path(\"model\")\n",
    "precision = \"FP16\"\n",
    "detection_model = \"horizontal-text-detection-0001\"\n",
    "recognition_model = \"text-recognition-0016\"\n",
    "base_model_dir = Path(\"~/open_model_zoo_models\").expanduser()\n",
    "omz_cache_dir = Path(\"~/open_model_zoo_cache\").expanduser()\n",
    "\n",
    "model_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_command = f\"omz_downloader --name {detection_model},{recognition_model} --output_dir {model_dir} --cache_dir {omz_cache_dir} --precision {precision}\"\n",
    "with yaspin(text=f\"Downloading {detection_model}, {recognition_model}\") as sp:\n",
    "    download_result = !$download_command\n",
    "    sp.text = f\"Finished downloading {detection_model}, {recognition_model}\"\n",
    "    sp.ok(\"âœ”\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_detection_path = Path(f\"{model_dir}/intel/{detection_model}/{precision}/{detection_model}\")\n",
    "text_recognition_encoder_path = Path(f\"{model_dir}/intel/{recognition_model}/{recognition_model}-encoder/{precision}/{recognition_model}-encoder\")\n",
    "text_recognition_decoder_path = Path(f\"{model_dir}/intel/{recognition_model}/{recognition_model}-decoder/{precision}/{recognition_model}-decoder\")\n",
    "assert Path(text_detection_path.with_suffix('.xml')).is_file(), \"Text detection model is not downloaded\"\n",
    "assert Path(text_recognition_encoder_path.with_suffix('.xml')).is_file(), \"Text recognition encoder is not downloaded\"\n",
    "assert Path(text_recognition_decoder_path.with_suffix('.xml')).is_file(), \"Text recognition decoder is not downlaoded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_model_file = ie.read_model(text_detection_path.with_suffix('.xml'))\n",
    "recognition_encoder_model_file = ie.read_model(text_recognition_encoder_path.with_suffix('.xml'))\n",
    "recognition_decoder_model_file = ie.read_model(text_recognition_decoder_path.with_suffix('.xml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdffile_name = \"175975.pdf\"\n",
    "doc = pdf.open(pdffile_name)\n",
    "pix = doc[11].get_pixmap(dpi=150)\n",
    "output = \"outfile.jpeg\"\n",
    "pix.save(output)\n",
    "image_file = \"outfile.jpeg\"\n",
    "image = cv2.imread(image_file)\n",
    "ih, iw, c = image.shape\n",
    "\n",
    "UUID_side = image[-int(ih/5):, int(iw/6):int(iw/6)+int(ih/5)]\n",
    "PID_side = image[-int(ih/6):, -int(ih/6):]\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_image_to_detection(image, model):\n",
    "    _, _, H, W = model.input(0).shape\n",
    "    resized_image = cv2.resize(image, (W, H))\n",
    "    return np.expand_dims(resized_image.transpose(2, 0, 1), 0)\n",
    "    \n",
    "\n",
    "UUID_side_resized = adjust_image_to_detection(UUID_side, detection_model_file)\n",
    "PID_side_resized = adjust_image_to_detection(PID_side, detection_model_file)\n",
    "\n",
    "assert UUID_side_resized.shape == PID_side_resized.shape == tuple(detection_model_file.input(0).shape), \"Invalid input shape\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_model_compiled = ie.compile_model(detection_model_file, device_name=\"CPU\")\n",
    "output_key = detection_model_compiled.output(\"boxes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UUID_boxes = detection_model_compiled([UUID_side_resized])[output_key]\n",
    "PID_boxes = detection_model_compiled([PID_side_resized])[output_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_empty = lambda box: box[~np.all(box == 0, axis = 1)]\n",
    "UUID_boxes_detected = remove_empty(UUID_boxes)\n",
    "PID_boxes_detected = remove_empty(PID_boxes)\n",
    "\n",
    "assert UUID_boxes_detected.shape[0] >= 1, \"No UUID detected\"\n",
    "assert PID_boxes_detected.shape[0] >= 1, \"No PID detected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PID_image_transposed = np.transpose(PID_side_resized[0], (1, 2, 0))\n",
    "x_min, y_min, x_max, y_max, prob = map(int, PID_boxes_detected[0])\n",
    "PID_cropped = PID_image_transposed[y_min:y_max, x_min:x_max]\n",
    "plt.imshow(PID_cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UUID_image_transposed = np.transpose(UUID_side_resized[0], (1, 2, 0))\n",
    "x_min, y_min, x_max, y_max, prob = map(int, UUID_boxes_detected[0])\n",
    "UUID_cropped = UUID_image_transposed[y_min:y_max, x_min:x_max]\n",
    "plt.imshow(UUID_cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_layer = recognition_encoder_model_file.input(0)\n",
    "partial_shape_encoder_input_layer = encoder_input_layer.partial_shape\n",
    "partial_shape_encoder_input_layer[3] = -1\n",
    "recognition_encoder_model_file.reshape({encoder_input_layer: partial_shape_encoder_input_layer})\n",
    "\n",
    "encoder_model_compiled = ie.compile_model(recognition_encoder_model_file, device_name=\"CPU\")\n",
    "decoder_model_compiled = ie.compile_model(recognition_decoder_model_file, device_name=\"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image_to_encoder(image, model):\n",
    "    N, C, H, W = model.input(0).partial_shape\n",
    "    IH, IW, IC = image.shape\n",
    "    scale_ratio = H.get_length() / IH\n",
    "    grayscale_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    resized_image = cv2.resize(\n",
    "        grayscale_image, None, fx=scale_ratio, fy=scale_ratio, interpolation=cv2.INTER_AREA\n",
    "    )\n",
    "    return resized_image[None, None,]\n",
    "    \n",
    "input_image_for_encoder = resize_image_to_encoder(UUID_cropped, encoder_model_compiled)\n",
    "output_key_encoder_features = encoder_model_compiled.output('features')\n",
    "output_key_encoder_hidden = encoder_model_compiled.output('decoder_hidden')\n",
    "\n",
    "encoder_output = encoder_model_compiled([input_image_for_encoder])\n",
    "\n",
    "encoder_output_features = encoder_output[output_key_encoder_features]\n",
    "encoder_output_hidden = encoder_output[output_key_encoder_hidden]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input_previous = decoder_model_compiled.input('decoder_input')\n",
    "decoder_input_features = decoder_model_compiled.input('features')\n",
    "decoder_input_hidden = decoder_model_compiled.input('hidden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_decoder_input_dict = {\n",
    "    decoder_input_previous: [0],\n",
    "    decoder_input_features: encoder_output_features,\n",
    "    decoder_input_hidden: encoder_output_hidden,\n",
    "}\n",
    "\n",
    "first_decoder_output = decoder_model_compiled(first_decoder_input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_output_hidden_key = decoder_model_compiled.output('decoder_hidden')\n",
    "decoder_output_value_key = decoder_model_compiled.output('decoder_output')\n",
    "\n",
    "decoder_output_hidden = first_decoder_output[decoder_output_hidden_key]\n",
    "decoder_output_value = first_decoder_output[decoder_output_value_key]\n",
    "\n",
    "alphabet = \"0123456789abcdefghijklmnopqrstuvwxyz\"\n",
    "alphabet = [symbol for symbol in alphabet]\n",
    "alphabet = [\"[START]\", \"[END]\", \" \", \"[NOT SURE]\"] + alphabet\n",
    "letter_idx = np.argmax(decoder_output_value)\n",
    "answer = \"\"\n",
    "while letter_idx not in [1, 2] and len(answer) < 10:\n",
    "    answer += alphabet[letter_idx]\n",
    "    decoder_input_dict = {\n",
    "        decoder_input_previous: [letter_idx],\n",
    "        decoder_input_features: encoder_output_features,\n",
    "        decoder_input_hidden: decoder_output_hidden,\n",
    "    }\n",
    "    decoder_output = decoder_model_compiled(decoder_input_dict)\n",
    "    decoder_output_hidden = decoder_output[decoder_output_hidden_key]\n",
    "    decoder_output_value = decoder_output[decoder_output_value_key]\n",
    "    letter_idx = np.argmax(decoder_output_value)\n",
    "\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_paths = {\n",
    "    \"encoder\": text_recognition_encoder_path,\n",
    "    \"decoder\": text_recognition_decoder_path,\n",
    "    \"detection\": text_detection_path\n",
    "}\n",
    "\n",
    "def map_UUID_to_trie(path):\n",
    "    trie = Trie()\n",
    "    files = [f[:-4] for f in listdir(path)]\n",
    "    trie.add_all(files)\n",
    "    return trie\n",
    "\n",
    "def resize_image_to_encoder(image, model):\n",
    "    N, C, H, W = model.input(0).partial_shape\n",
    "    IH, IW, IC = image.shape\n",
    "    scale_ratio = H.get_length() / IH\n",
    "    grayscale_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    resized_image = cv2.resize(\n",
    "        grayscale_image, None, fx=scale_ratio, fy=scale_ratio, interpolation=cv2.INTER_AREA\n",
    "    )\n",
    "    return resized_image[None, None,]\n",
    "\n",
    "def prepare_alphabet():\n",
    "    alphabet = \"0123456789abcdefghijklmnopqrstuvwxyz\"\n",
    "    alphabet = [symbol for symbol in alphabet]\n",
    "    return [\"[START]\", \"[END]\", \" \", \"[NOT SURE]\"] + alphabet\n",
    "\n",
    "def pipeline(image: np.array, model_paths: dict, image_proportion: float = 0.2, width_offset: float = 1/6):\n",
    "    detection_model_compiled, encoder_model_compiled, decoder_model_compiled = initialize_models(model_paths)\n",
    "    ih, iw, _ = image.shape\n",
    "    alphabet = prepare_alphabet()\n",
    "    UUID_side = image[-int(ih*image_proportion):, int(iw*width_offset):int(iw*width_offset)+int(ih*image_proportion)]\n",
    "    PID_side = image[-int(ih*image_proportion):, -int(ih*image_proportion):]\n",
    "    UUID_PID = []\n",
    "    for name, partial_image in zip((\"UUID\", \"PID\"), (UUID_side, PID_side)):\n",
    "        preprocessed_image = adjust_image_to_detection(partial_image, detection_model_compiled)\n",
    "        boxes = detect_boxes(preprocessed_image, detection_model_compiled)\n",
    "        assert boxes.shape[0] >= 1, f\"Boxes shape: {boxes.shape}\"\n",
    "        if boxes.shape[0] > 1:\n",
    "            if name == \"UUID\":\n",
    "                boxes = sorted(boxes, key=lambda value: value[2]-value[0], reverse=True) \n",
    "            elif name == \"PID\":\n",
    "                boxes = sorted(boxes, key=lambda value: value[3], reverse=True)\n",
    "        preprocessed_image = np.transpose(preprocessed_image[0], (1, 2, 0))\n",
    "        x_min, y_min, x_max, y_max, _ = map(int, boxes[0])\n",
    "        image_cropped = preprocessed_image[y_min:y_max, x_min:x_max]\n",
    "        image_resized = resize_image_to_encoder(image_cropped, encoder_model_compiled)\n",
    "        features_encoder, hidden_encoder = run_encoder_model(image_resized, encoder_model_compiled)\n",
    "        decoder_input_previous = decoder_model_compiled.input('decoder_input')\n",
    "        decoder_input_features = decoder_model_compiled.input('features')\n",
    "        decoder_input_hidden = decoder_model_compiled.input('hidden')\n",
    "        decoder_input_dict = {\n",
    "            decoder_input_previous: [0],\n",
    "            decoder_input_features: features_encoder,\n",
    "            decoder_input_hidden: hidden_encoder,\n",
    "        }\n",
    "        hidden_decoder, value_decoder = run_decoder_model(decoder_input_dict, decoder_model_compiled)\n",
    "        answer = \"\"\n",
    "        while value_decoder not in (1, 2) and len(answer) <= 13:\n",
    "            answer += alphabet[value_decoder]\n",
    "            decoder_input_dict[decoder_input_previous] = [value_decoder]\n",
    "            decoder_input_dict[decoder_input_hidden] = hidden_decoder\n",
    "            hidden_decoder, value_decoder = run_decoder_model(decoder_input_dict, decoder_model_compiled)\n",
    "        UUID_PID.append(answer)\n",
    "    return UUID_PID\n",
    "\n",
    "def check_if_correct(UUID, trie):\n",
    "    if UUID in trie:\n",
    "        return UUID\n",
    "    else:\n",
    "        possible_matches = trie.search_within_distance(UUID, dist=1)\n",
    "        if len(possible_matches) == 0:\n",
    "            possible_matches = trie.search_within_distance(UUID, dist=1)\n",
    "\n",
    "def initialize_models(models_paths: dict):\n",
    "    detection_model_file = ie.read_model(models_paths[\"detection\"].with_suffix('.xml'))\n",
    "    recognition_encoder_model_file = ie.read_model(models_paths[\"encoder\"].with_suffix('.xml'))\n",
    "    recognition_decoder_model_file = ie.read_model(models_paths[\"decoder\"].with_suffix('.xml'))\n",
    "    encoder_input_layer = recognition_encoder_model_file.input(0)\n",
    "    partial_shape_encoder_input_layer = encoder_input_layer.partial_shape\n",
    "    partial_shape_encoder_input_layer[3] = -1\n",
    "    recognition_encoder_model_file.reshape({encoder_input_layer: partial_shape_encoder_input_layer})\n",
    "\n",
    "    detection_model_compiled = ie.compile_model(detection_model_file, device_name=\"CPU\")\n",
    "    encoder_model_compiled = ie.compile_model(recognition_encoder_model_file, device_name=\"CPU\")\n",
    "    decoder_model_compiled = ie.compile_model(recognition_decoder_model_file, device_name=\"CPU\")\n",
    "    return detection_model_compiled, encoder_model_compiled, decoder_model_compiled\n",
    "\n",
    "def detect_boxes(image, model) -> np.array:\n",
    "    remove_empty = lambda box: box[~np.all(box == 0, axis = 1)]\n",
    "    output_key = model.output(\"boxes\")\n",
    "    return remove_empty(model([image])[output_key])\n",
    "\n",
    "def run_encoder_model(image, model):\n",
    "    output_key_encoder_features = model.output('features')\n",
    "    output_key_encoder_hidden = model.output('decoder_hidden')\n",
    "    encoder_output = model([image])\n",
    "    encoder_output_features = encoder_output[output_key_encoder_features]\n",
    "    encoder_output_hidden = encoder_output[output_key_encoder_hidden]\n",
    "    return encoder_output_features, encoder_output_hidden\n",
    "\n",
    "def run_decoder_model(inputs, model):\n",
    "    decoder_model_output = model(inputs)\n",
    "    decoder_output_hidden_key = model.output('decoder_hidden')\n",
    "    decoder_output_value_key = model.output('decoder_output')\n",
    "    decoder_output_hidden = decoder_model_output[decoder_output_hidden_key]\n",
    "    decoder_output_value = decoder_model_output[decoder_output_value_key]\n",
    "    return decoder_output_hidden, np.argmax(decoder_output_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trie = map_UUID_to_trie('/home/jakubdeb/repo/splinter/research/answers/answers')\n",
    "\n",
    "pdffile_name = \"175975.pdf\"\n",
    "doc = pdf.open(pdffile_name)\n",
    "scan_set = []\n",
    "for page in range(doc.page_count):\n",
    "    pix = doc[page].get_pixmap(dpi=150)\n",
    "    output = \"outfile.jpeg\"\n",
    "    pix.save(output)\n",
    "    image_file = \"outfile.jpeg\"\n",
    "    image = cv2.imread(image_file)\n",
    "    scan_set.append(pipeline(image, model_paths))\n",
    "\n",
    "for idx, (uuid, pid) in enumerate(scan_set):\n",
    "    if uuid not in trie:\n",
    "        if idx > 0:\n",
    "            if hamming(uuid, scan_set[idx-1][0]) <= 2 and scan_set[idx-1][0] in trie:\n",
    "                scan_set[idx][0] = scan_set[idx-1][0]\n",
    "        if idx < len(scan_set) - 1 and scan_set[idx][0] not in trie:\n",
    "            if hamming(uuid, scan_set[idx+1][0]) <= 2 and scan_set[idx+1][0] in trie:\n",
    "                scan_set[idx][0] = scan_set[idx+1][0]\n",
    "        if scan_set[idx][0] not in trie:\n",
    "            possible_matches = trie.search_within_distance(scan_set[idx][0], dist=1)\n",
    "            if len(possible_matches) == 1:\n",
    "                scan_set[idx][0] = possible_matches[0]\n",
    "            else:\n",
    "                print(f'DETECTED UUID: {uuid} POSSIBLE MATCHES: {possible_matches}, ABSOLUTE PAGE NO: {idx}') \n",
    "\n",
    "pages_to_exams = {}\n",
    "for idx, (uuid, pid) in enumerate(scan_set):\n",
    "    if uuid in pages_to_exams.keys():\n",
    "        pages_to_exams[uuid].append([idx, pid])\n",
    "    else:\n",
    "        pages_to_exams[uuid] = [[idx, pid]]\n",
    "\n",
    "for key, value in pages_to_exams.items():\n",
    "    pages_to_exams[key] = [v[0] for v in sorted(value, key=lambda x: x[1])]\n",
    "\n",
    "for key, value in pages_to_exams.items():\n",
    "    output_doc = pdf.open()\n",
    "    for page in value:\n",
    "        output_doc.insert_pdf(doc, from_page=page, to_page=page)\n",
    "    output_doc.save(f'dataset/{key}.pdf')\n",
    "\n",
    "print(pages_to_exams)\n",
    "        \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74283e06228d4494a659e92a437093ac62ef0b0f163ddec465853a074f32f723"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
